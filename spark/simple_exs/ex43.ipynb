{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Ex. 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputPathReadings = \"/data/students/bigdata-01QYD/ex_data/Ex43/data/readings.txt\"\n",
    "#inputPathNeighbors = \"/data/students/bigdata-01QYD/ex_data/Ex43/data/neighbors.txt\"\n",
    "#outputPath = \"res_out_Ex43/\"\n",
    "#outputPath2 = \"res_out_Ex43_2/\"\n",
    "#outputPath3 = \"res_out_Ex43_3/\"\n",
    "#thresholdFreeSlots = 3\n",
    "#thresholdCriticalPercentage = 0.8\n",
    "\n",
    "inputPathReadings = \"data/Ex43/data/readings.txt\"\n",
    "inputPathNeighbors = \"data/Ex43/data/neighbors.txt\"\n",
    "outputPath = \"res_out_Ex43/\"\n",
    "outputPath2 = \"res_out_Ex43_2/\"\n",
    "outputPath3 = \"res_out_Ex43_3/\"\n",
    "thresholdFreeSlots = 3\n",
    "thresholdCriticalPercentage = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Ex. 43 - part I\n",
    "# Selection of the stations with a percentage of critical situations\n",
    "# greater than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the readings file\n",
    "readingsRDD = sc.textFile(inputPathReadings).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criticalSituation(line):\n",
    "    fields = line.split(\",\")\n",
    "    # fields[0] is the station id\n",
    "    # fields[5] is the number of free slots\n",
    "    stationId = fields[0]\n",
    "    numFreeSlots = int(fields[5])\n",
    "    \n",
    "    if  numFreeSlots < thresholdFreeSlots:\n",
    "        return (stationId, (1, 1))\n",
    "    else:\n",
    "        return (stationId, (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of total and critical readings for each station\n",
    "# Create an RDD of pairs with\n",
    "# key: stationId\n",
    "# value: (numReadings, numCriticalReadings)\n",
    "# ------- numReadings: 1 for each input line\n",
    "# --------numCriticalReadings: 0 if the situation is not critical. 1 if it is critical\n",
    "stationCountPairRDD = readingsRDD.map(criticalSituation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationCountPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of total and critical readings for each station\n",
    "stationTotalCountPairRDD = stationCountPairRDD\\\n",
    ".reduceByKey(lambda c1, c2: (c1[0]+c2[0], c1[1]+c2[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationTotalCountPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentage of critical situations for each station\n",
    "stationPercentagePairRDD = stationTotalCountPairRDD\\\n",
    ".mapValues(lambda counters: counters[1]/counters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stationPercentagePairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stations with percentage > 80%\n",
    "selectedStationsPairRDD = stationPercentagePairRDD\\\n",
    ".filter(lambda sensorPerc: sensorPerc[1]>thresholdCriticalPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedStationsPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the stored stations by decreasing percentage of critical situations\n",
    "selectedStationsSortedPairRDD = selectedStationsPairRDD\\\n",
    ".sortBy(lambda sensorPerc: sensorPerc[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedStationsSortedPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedStationsSortedPairRDD.saveAsTextFile(outputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Ex. 43 - part II\n",
    "# Selection of the pairs (timeslot, station) with a percentage of\n",
    "# critical situations greater than 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criticalSituationTimeslots(line):\n",
    "    \n",
    "    fields = line.split(\",\")\n",
    "\n",
    "    # fields[0] is the station id\n",
    "    # fields[2] is the hour\n",
    "    # fields[5] is the number of free slots\n",
    "\n",
    "    stationId = fields[0]\n",
    "    numFreeSlots = int(fields[5])\n",
    "    \n",
    "    minTimeslotHour = 4 * ( int(fields[2]) // int(4))\n",
    "    maxTimeslotHour = minTimeslotHour + 3\n",
    "\n",
    "    timestamp = \"ts[\" + str(minTimeslotHour) + \"-\" + str(maxTimeslotHour) + \"]\"\n",
    "    \n",
    "    key = (timestamp, stationId)\n",
    "    \n",
    "    if  numFreeSlots < thresholdFreeSlots:\n",
    "        return (key, (1, 1))\n",
    "    else:\n",
    "        return (key, (1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data are already in readingsRDD\n",
    "\n",
    "# Count the number of total and critical readings for each (timeslot,stationId)\n",
    "# Create an RDD of pairs with\n",
    "# key: (timeslot,stationId)\n",
    "# value: (numReadings, numCriticalReadings)\n",
    "# ------- numReadings: 1 for each input line\n",
    "# --------numCriticalReadings: 0 if the situation is not critical. 1 if it is critical\n",
    "\n",
    "timestampStationCountPairRDD = readingsRDD.map(criticalSituationTimeslots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestampStationCountPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of total and critical readings for each (timeslot,station)\n",
    "timestampStationTotalCountPairRDD = timestampStationCountPairRDD \\\n",
    ".reduceByKey(lambda c1, c2: (c1[0]+c2[0], c1[1]+c2[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestampStationTotalCountPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the percentage of critical situations for each (timeslot,station)\n",
    "timestampStationPercentagePairRDD = timestampStationTotalCountPairRDD\\\n",
    ".mapValues(lambda counters: counters[1]/counters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestampStationPercentagePairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (timeslot,station) pairs with percentage > 80%\n",
    "selectedTimestampStationsPairRDD = timestampStationPercentagePairRDD\\\n",
    ".filter(lambda sensorPerc: sensorPerc[1]>thresholdCriticalPercentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedTimestampStationsPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the stored pairs by decreasing percentage of critical situations\n",
    "percentageTimestampStationsSortedPairRDD = selectedTimestampStationsPairRDD\\\n",
    ".sortBy(lambda sensorPerc: sensorPerc[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentageTimestampStationsSortedPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentageTimestampStationsSortedPairRDD.saveAsTextFile(outputPath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Ex. 43 - part III\n",
    "# Select a reading (i.e., a line) of the first input file if and only if the following constraints are true\n",
    "# - The line is associated with a full station situation\n",
    "# - All the neighbor stations of the station Si are full in the time stamp associated with the current line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file containing the list of neighbors for each station\n",
    "neighborsRDD = sc.textFile(inputPathNeighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each line of the input file to a pair stationid, list of neighbor stations\n",
    "nPairRDD = neighborsRDD.map(lambda line: (line.split(\",\")[0], line.split(\",\")[1].split(\" \")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local dictionary in the main memory of the driver that will be used to store the mapping \n",
    "# stationid -> list of neighbors\n",
    "# There are only 100 stations. Hence, you can suppose that data about neighbors can be stored in the main memory\n",
    "neighbors=nPairRDD.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input data are already in readingsRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the lines/readings associated with a full status (number of free slots equal to 0)\n",
    "fullStatusLines = readingsRDD.filter(lambda line: int(line.split(\",\")[5])==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTimestamp(reading):\n",
    "    fields = reading.split(\",\")\n",
    "    timestamp = fields[1] + fields[2] + fields[3]\n",
    "    \n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD of pairs with key = timestamp and value=reading associated with that timestamp\n",
    "# The concatenation of fields[1], fields[2], fields[3] is the timestamp of the reading\n",
    "fullLinesPRDD = fullStatusLines.map(lambda reading: (extractTimestamp(reading), reading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullLinesPRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Collapse all the values with the same key in one single pair (timestamp, reading associated with that timestamp)\n",
    "fullReadingsPerTimestamp = fullLinesPRDD.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fullReadingsPerTimestamp.mapValues(lambda v: list(v)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectReadingssFunc(pairTimeStampListReadings):\n",
    "    # Extract the list of stations that appear in the readings\n",
    "    # associated with the current key \n",
    "    # (i.e., the list of stations that are full in this timestamp)\n",
    "    # The list of readings is in the value part of the inpput key-value pair\n",
    "    stations = []\n",
    "    for reading in pairTimeStampListReadings[1]:\n",
    "        # Extract the stationid from each reading\n",
    "        fields = reading.split(\",\")\n",
    "        stationId = fields[0]\n",
    "        stations.append(stationId)\n",
    "        \n",
    "        \n",
    "    # Iterate again over the list of readings to select the readings satistying the constraint on the \n",
    "    # full status situation of all neighboors \n",
    "    selectedReading = []\n",
    "\n",
    "    for reading in pairTimeStampListReadings[1]:\n",
    "        # This reading must be selected if all the neighbors of\n",
    "        # the station of this reading are also in the value of\n",
    "        # the current key-value pair (i.e., if they are in list stations)\n",
    "        # Extract the stationid of this reading\n",
    "        fields = reading.split(\",\")\n",
    "        stationId = fields[0]\n",
    "\n",
    "        # Select the list of neighbors of the current station\n",
    "        nCurrentStation = neighbors[stationId]\n",
    "        \n",
    "        # Check if all the neighbors of the current station are in value \n",
    "        # (i.e., the local list stations) of the current key-value pair\n",
    "        allNeighborsFull = True\n",
    "        \n",
    "        for neighborStation in nCurrentStation:\n",
    "            if neighborStation not in stations:\n",
    "                # There is at least one neighbor of th current station\n",
    "                # that is not in the full status in this timestamp\n",
    "                allNeighborsFull = False\n",
    "                \n",
    "        if allNeighborsFull == True:\n",
    "            selectedReading.append(reading)\n",
    "            \n",
    "    return selectedReading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each pair contains a timestamp and the list of readings (with number of free slots equal to 0) \n",
    "# associated with that timestamp.\n",
    "# Check, for each reading in the list, if all the neighbors of the station of that reading are \n",
    "# also present in this list of readings\n",
    "# Emit one \"string\" for each reading associated with a completely full status \n",
    "selectedReadingsRDD = fullReadingsPerTimestamp.flatMap(selectReadingssFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectedReadingsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result in HDFS\n",
    "selectedReadingsRDD.saveAsTextFile(outputPath3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
