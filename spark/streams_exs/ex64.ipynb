{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historicalInputFile = \"data/Ex64/data/historicalData.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the historical data and compute the maximum and minimum price for each stock\n",
    "# Non-streaming RDD\n",
    "historicalDataRDD = sc.textFile(historicalInputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return one pair (stockId, (price, price) )  for each input record\n",
    "def extractStockIdPricePrice(line):\n",
    "    fields = line.split(\",\")\n",
    "    \n",
    "    stockId = fields[1]\n",
    "    price = fields[2]\n",
    "    \n",
    "    return (stockId, (float(price), float(price)) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stockIdPriceHistoricalRDD = historicalDataRDD.map(extractStockIdPricePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max and min for each stockId based on the historical data\n",
    "stockIdPriceHistoricalMaxMinRDD = stockIdPriceHistoricalRDD\\\n",
    ".reduceByKey(lambda v1, v2: ( max(v1[0],v2[0]), min(v1[1],v2[1]) ) ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Streaming Context object\n",
    "#ssc = StreamingContext(sc, 60)\n",
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a (Receiver) DStream that will connect to localhost:9999\n",
    "pricesDStream = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join on the stockid each input record of the input stream with the \n",
    "# content of stockIdPriceHistoricalMaxMinRDD to retrieve \n",
    "# the historical maximum-minimum range of the stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return one pair (stockId,price) for each input record\n",
    "stockIdPriceDStream = pricesDStream.map(lambda record: ( record.split(\",\")[1] , float(record.split(\",\")[2])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the RDD associated with the content of the current batch and \n",
    "# the non-streaming RDD stockIdPriceHistoricalMaxMinRDD\n",
    "stockIdPriceMaxMinDStream = stockIdPriceDStream\\\n",
    ".transform(lambda batchRDD: batchRDD.join(stockIdPriceHistoricalMaxMinRDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only lines with price > maximum historical price \n",
    "# or price < minimum historical price\n",
    "def anomalyValue(pair):\n",
    "    currentPrice = pair[1][0]\n",
    "    stockHistoricalMaxPrice = pair[1][1][0]\n",
    "    stockHistoricalMinPrice = pair[1][1][1]\n",
    "    \n",
    "    if currentPrice>stockHistoricalMaxPrice or currentPrice<stockHistoricalMinPrice:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "\n",
    "selectedStockPricesDStream = stockIdPriceMaxMinDStream.filter(anomalyValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve only the stockIDs and apply distinct to remove duplicates\n",
    "# keys and distinct are not available for DStreams.\n",
    "# transform must be used\n",
    "selectStockIdsDStream = selectedStockPricesDStream\\\n",
    ".transform(lambda batchRDD: batchRDD.keys().distinct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectStockIdsDStream.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the computation\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this application for 90 seconds\n",
    "ssc.awaitTerminationOrTimeout(90)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
