{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second version. This version is more efficient than the previous one \n",
    "# because the amount of joined data is reduced.\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historicalInputFile = \"data/Ex64/data/historicalData.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the historical data and compute the maximum and minimum price for each stock\n",
    "# Non-streaming RDD\n",
    "historicalDataRDD = sc.textFile(historicalInputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return one pair (stockId, (price, price) )  for each input record\n",
    "def extractStockIdPricePrice(line):\n",
    "    fields = line.split(\",\")\n",
    "    \n",
    "    stockId = fields[1]\n",
    "    price = fields[2]\n",
    "    \n",
    "    return (stockId, (float(price), float(price)) )\n",
    "\n",
    "\n",
    "stockIdPriceHistoricalRDD = historicalDataRDD.map(extractStockIdPricePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max and min for each stockId based on the historical data\n",
    "stockIdPriceHistoricalMaxMinRDD = stockIdPriceHistoricalRDD\\\n",
    ".reduceByKey(lambda v1, v2: ( max(v1[0],v2[0]), min(v1[1],v2[1]) ) ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Streaming Context object\n",
    "#ssc = StreamingContext(sc, 60)\n",
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a (Receiver) DStream that will connect to localhost:9999\n",
    "pricesDStream = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute max and min for each stockId of each input batch\n",
    "stockIdPriceDStream = pricesDStream.map(extractStockIdPricePrice)\\\n",
    ".reduceByKey(lambda v1, v2: ( max(v1[0],v2[0]), min(v1[1],v2[1]) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join stockIdPriceDStream with stockIdPriceHistoricalMaxMinRDD\n",
    "# Join the RDD associated with the content of the current batch and \n",
    "# the non-streaming RDD stockIdPriceHistoricalMaxMinRDD\n",
    "stockIdPriceMaxMinDStream = stockIdPriceDStream\\\n",
    ".transform(lambda batchRDD: batchRDD.join(stockIdPriceHistoricalMaxMinRDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only stocks with stream max price > maximum historical price \n",
    "# or stream min price < minimum historical price\n",
    "def anomalyValue(pair):\n",
    "    stockBatchMaxPrice = pair[1][0][0]\n",
    "    stockBatchMinPrice = pair[1][0][1]\n",
    "    \n",
    "    stockHistoricalMaxPrice = pair[1][1][0]\n",
    "    stockHistoricalMinPrice = pair[1][1][1]\n",
    "    \n",
    "    if stockBatchMaxPrice>stockHistoricalMaxPrice or stockBatchMinPrice<stockHistoricalMinPrice:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "\n",
    "selectedStockPricesDStream = stockIdPriceMaxMinDStream\\\n",
    ".filter(anomalyValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve only the stockIDs of the selected stocks\n",
    "# keys is not available for DStreams.\n",
    "# transform must be used or map\n",
    "selectStockIdsDStream = selectedStockPricesDStream\\\n",
    ".transform(lambda batchRDD: batchRDD.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectStockIdsDStream.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the computation\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this application for 90 seconds\n",
    "ssc.awaitTerminationOrTimeout(90)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
