{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark Streaming Context object\n",
    "ssc = StreamingContext(sc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileStations = \"data/Ex63/data/stations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Standard\" RDD associated with the characteristics of the stations\n",
    "# Extract (stationId, name)\n",
    "stationNameRDD = sc.textFile(inputFileStations)\\\n",
    ".map(lambda line: (line.split(\"\\t\")[0], line.split(\"\\t\")[3]) ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a (Receiver) DStream that will connect to localhost:9999\n",
    "readingsDStream = ssc.socketTextStream(\"localhost\", 9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each readings has the format:\n",
    "# stationId,#free slots,#used slots,timestamp\n",
    "# Select readings with num. free slots = 0\n",
    "fullReadingsDStream = readingsDStream.filter(lambda line: int(line.split(\",\")[1])==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pairs (stationId, timestamp)\n",
    "stationIdTimestampDStream = fullReadingsDStream.map(lambda line: (line.split(\",\")[0],line.split(\",\")[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the content of the DStream with the \"standard\" RDD to retrieve\n",
    "# the name of each station. \n",
    "# To perform this join between streaming and\n",
    "# non-streaming RDDs the transform transformation must be used\n",
    "joinDStream = stationIdTimestampDStream.transform(lambda batchRDD: batchRDD.join(stationNameRDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract (name of the station, timestamp)\n",
    "# It is the value part of the returned pairs\n",
    "stationNameTimestampDStream = joinDStream.map(lambda pair: pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationNameTimestampDStream.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the computation\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this application for 90 seconds\n",
    "ssc.awaitTerminationOrTimeout(90)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
